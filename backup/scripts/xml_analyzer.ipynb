{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cb6c31e",
   "metadata": {},
   "source": [
    "# Xml analyzer\n",
    "\n",
    "Single-run, streaming analysis of an mzML file that computes run summaries, infers DDA/DIA acquisition mode, builds a deduplicated Structure Report, extracts selectedIon summaries, and writes tidy artifacts (JSON + CSV/Parquet). Set inputs below and Run All."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2fa7f0",
   "metadata": {},
   "source": [
    "## 1) Install and Import Dependencies\n",
    "\n",
    "This notebook installs minimal deps if missing (lxml, pandas, tqdm). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0557b7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing lxml...\n",
      "Collecting lxml\n",
      "  Downloading lxml-6.0.2-cp312-cp312-macosx_10_13_universal2.whl.metadata (3.6 kB)\n",
      "Downloading lxml-6.0.2-cp312-cp312-macosx_10_13_universal2.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lxml\n",
      "Successfully installed lxml-6.0.2\n",
      "Using parser backend: lxml\n"
     ]
    }
   ],
   "source": [
    "# Auto-install light deps if missing\n",
    "import importlib, sys, subprocess\n",
    "\n",
    "def _ensure(pkg: str, module: str | None = None):\n",
    "    mod = module or pkg\n",
    "    try:\n",
    "        importlib.import_module(mod)\n",
    "    except ImportError:\n",
    "        try:\n",
    "            print(f\"Installing {pkg}...\")\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: failed to install {pkg}: {e}\")\n",
    "\n",
    "for pkg, mod in [(\"lxml\", \"lxml\"), (\"pandas\", \"pandas\")]:\n",
    "    _ensure(pkg, mod)\n",
    "\n",
    "# Imports\n",
    "import os, io, json, time, logging, struct, base64, zlib, math, csv\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import Optional, Dict, List, Any, Iterable, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Parser backend (try lxml)\n",
    "try:\n",
    "    from lxml import etree as ET\n",
    "    PARSER_BACKEND = \"lxml\"\n",
    "    def get_iterparse_kwargs() -> Dict[str, Any]:\n",
    "        return dict(resolve_entities=False, no_network=True, huge_tree=False, recover=False, remove_pis=True, remove_comments=True)\n",
    "except Exception:\n",
    "    import xml.etree.ElementTree as ET\n",
    "    PARSER_BACKEND = \"xml.etree.ElementTree\"\n",
    "    def get_iterparse_kwargs() -> Dict[str, Any]:\n",
    "        return {}\n",
    "\n",
    "print(f\"Using parser backend: {PARSER_BACKEND}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d88e2a",
   "metadata": {},
   "source": [
    "## 2) Inputs & Controls\n",
    "\n",
    "Set your inputs once, then Run All."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7254aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "- MZML_FILE: /Users/maxvandenboom/Docs/Coding/AI/ProfileTensor/data/2449SAB_0002_A1.mzML\n",
      "- OUTPUT_DIR: ../out/2449SAB_0002_A1\n",
      "- MAX_SPECTRA_SAMPLE: 0\n",
      "- PREVIEW_ROWS: 10\n",
      "- ACQ_DDA_THRESHOLD: 0.8\n",
      "- ACQ_DIA_THRESHOLD: 0.8\n"
     ]
    }
   ],
   "source": [
    "# User-friendly controls\n",
    "\n",
    "# Defaults\n",
    "MZML_FILE: str = \"/Users/maxvandenboom/Docs/Coding/AI/ProfileTensor/data/2449SAB_0002_A1.mzML\"  # change to your file\n",
    "OUTPUT_DIR: str = \"../out/2449SAB_0002_A1\"\n",
    "MAX_SPECTRA_SAMPLE: int = 0         # 0 = process all spectra\n",
    "PREVIEW_ROWS: int = 10\n",
    "ACQ_DDA_THRESHOLD: float = 0.80\n",
    "ACQ_DIA_THRESHOLD: float = 0.80\n",
    "\n",
    "print(\"Config:\")\n",
    "print(\"- MZML_FILE:\", MZML_FILE)\n",
    "print(\"- OUTPUT_DIR:\", OUTPUT_DIR)\n",
    "print(\"- MAX_SPECTRA_SAMPLE:\", MAX_SPECTRA_SAMPLE)\n",
    "print(\"- PREVIEW_ROWS:\", PREVIEW_ROWS)\n",
    "print(\"- ACQ_DDA_THRESHOLD:\", ACQ_DDA_THRESHOLD)\n",
    "print(\"- ACQ_DIA_THRESHOLD:\", ACQ_DIA_THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642f454b",
   "metadata": {},
   "source": [
    "## 3) Secure Path Validation and Output Directory Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6820f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts will be written to:\n",
      "- /Users/maxvandenboom/Docs/Coding/AI/ProfileTensor/out/2449SAB_0002_A1/run_summary.json\n",
      "- /Users/maxvandenboom/Docs/Coding/AI/ProfileTensor/out/2449SAB_0002_A1/acquisition_report.json\n",
      "- /Users/maxvandenboom/Docs/Coding/AI/ProfileTensor/out/2449SAB_0002_A1/structure_report.json\n",
      "- /Users/maxvandenboom/Docs/Coding/AI/ProfileTensor/out/2449SAB_0002_A1/spectra_meta.csv\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "def validate_path(file_path: str, allowed_root: Path | None = None) -> Path:\n",
    "    p = Path(file_path).expanduser()\n",
    "    if not p.exists() or not p.is_file():\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    if allowed_root is not None:\n",
    "        try:\n",
    "            p.resolve(strict=True).relative_to(Path(allowed_root).resolve())\n",
    "        except Exception:\n",
    "            # Allow explicit absolute path but warn\n",
    "            print(f\"Warning: {p} is outside the allowed root {allowed_root}. Proceeding anyway.\")\n",
    "    return p.resolve(strict=True)\n",
    "\n",
    "# Prepare output directory and artifact paths\n",
    "OUTDIR = Path(OUTPUT_DIR).resolve()\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "if not os.access(OUTDIR, os.W_OK):\n",
    "    raise PermissionError(f\"Cannot write to output directory: {OUTDIR}\")\n",
    "\n",
    "RUN_SUMMARY_JSON = OUTDIR / 'run_summary.json'\n",
    "ACQ_REPORT_JSON = OUTDIR / 'acquisition_report.json'\n",
    "STRUCTURE_JSON = OUTDIR / 'structure_report.json'\n",
    "SPECTRA_META_CSV = OUTDIR / 'spectra_meta.csv'\n",
    "\n",
    "print(\"Artifacts will be written to:\")\n",
    "print(\"-\", RUN_SUMMARY_JSON)\n",
    "print(\"-\", ACQ_REPORT_JSON)\n",
    "print(\"-\", STRUCTURE_JSON)\n",
    "print(\"-\", SPECTRA_META_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbc0c55",
   "metadata": {},
   "source": [
    "## 4) Parser Backend and Namespace Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b4d969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MZML_NS = {\"mzml\": \"http://psi.hupo.org/ms/mzml\"}\n",
    "\n",
    "def strip_ns(tag: str) -> str:\n",
    "    return tag.split('}', 1)[1] if '}' in tag else tag\n",
    "\n",
    "def get_ns_tag(local_name: str) -> str:\n",
    "    return f\"{{{MZML_NS['mzml']}}}{local_name}\"\n",
    "\n",
    "def _local(tag: str) -> str:\n",
    "    return tag.split('}', 1)[-1] if '}' in tag else tag\n",
    "\n",
    "def _findall(elem, xpath: str):\n",
    "    # Use wildcard ns\n",
    "    return elem.findall(xpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a74479a",
   "metadata": {},
   "source": [
    "## 5) Data Models and Structured Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56d4e608",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SpectrumSummary:\n",
    "    index: int\n",
    "    id: str\n",
    "    ms_level: Optional[int]\n",
    "    polarity: Optional[str] = None\n",
    "    centroid: Optional[bool] = None\n",
    "    tic: Optional[float] = None\n",
    "    base_peak_mz: Optional[float] = None\n",
    "    base_peak_intensity: Optional[float] = None\n",
    "    rt_seconds: Optional[float] = None\n",
    "\n",
    "@dataclass\n",
    "class MzMLSummary:\n",
    "    file_path: str\n",
    "    file_size_bytes: int\n",
    "    parser_backend: str\n",
    "    mzml_id: Optional[str] = None\n",
    "    mzml_version: Optional[str] = None\n",
    "    run_id: Optional[str] = None\n",
    "    start_timestamp: Optional[str] = None\n",
    "    cv_count: int = 0\n",
    "    software_count: int = 0\n",
    "    instrument_count: int = 0\n",
    "    data_processing_count: int = 0\n",
    "    total_spectra: int = 0\n",
    "    spectra_sampled: int = 0\n",
    "    ms_level_distribution: Dict[int, int] = field(default_factory=dict)\n",
    "    centroid_count: int = 0\n",
    "    profile_count: int = 0\n",
    "    tic_range: Optional[Tuple[float, float]] = None\n",
    "    base_peak_mz_range: Optional[Tuple[float, float]] = None\n",
    "    base_peak_intensity_range: Optional[Tuple[float, float]] = None\n",
    "    rt_range: Optional[Tuple[float, float]] = None\n",
    "    compression_counts: Dict[str, int] = field(default_factory=dict)   # {'zlib': n, 'none': n}\n",
    "    bit_depth_counts: Dict[str, int] = field(default_factory=dict)     # {'32': n, '64': n}\n",
    "    parse_duration_sec: float = 0.0\n",
    "\n",
    "class StructuredLogger:\n",
    "    def __init__(self, name: str = \"mzml_end2end\", level: int = logging.INFO):\n",
    "        self.logger = logging.getLogger(name)\n",
    "        self.logger.setLevel(level)\n",
    "        if not self.logger.handlers:\n",
    "            h = logging.StreamHandler(sys.stdout)\n",
    "            h.setFormatter(logging.Formatter('%(message)s'))\n",
    "            self.logger.addHandler(h)\n",
    "    def _emit(self, level: str, event: str, **kv):\n",
    "        payload = {\"ts\": time.time(), \"level\": level, \"event\": event, **kv}\n",
    "        self.logger.log(getattr(logging, level), json.dumps(payload))\n",
    "    def info(self, event: str, **kv):\n",
    "        self._emit(\"INFO\", event, **kv)\n",
    "    def warning(self, event: str, **kv):\n",
    "        self._emit(\"WARNING\", event, **kv)\n",
    "    def error(self, event: str, **kv):\n",
    "        self._emit(\"ERROR\", event, **kv)\n",
    "\n",
    "logger = StructuredLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866dac9d",
   "metadata": {},
   "source": [
    "## 6) Single-Pass Streaming Analyzer (Run Metrics + Acquisition + Structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c224c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV accessions of interest\n",
    "ACC_MS_LEVEL = \"MS:1000511\"\n",
    "ACC_SELECTED_ION_MZ = \"MS:1000744\"\n",
    "ACC_ISO_TARGET = \"MS:1000827\"\n",
    "ACC_ISO_WIDTH = {\"MS:1000826\", \"MS:1000828\", \"MS:1000829\"}  # offsets + width related\n",
    "\n",
    "class Reservoir:\n",
    "    def __init__(self, k: int = 200):\n",
    "        self.k = k\n",
    "        self.buf: List[float] = []\n",
    "        self.n = 0\n",
    "    def add(self, x: float):\n",
    "        import random\n",
    "        self.n += 1\n",
    "        if len(self.buf) < self.k:\n",
    "            self.buf.append(x)\n",
    "        else:\n",
    "            j = random.randint(1, self.n)\n",
    "            if j <= self.k:\n",
    "                self.buf[j - 1] = x\n",
    "    def sample(self) -> List[float]:\n",
    "        return list(self.buf)\n",
    "\n",
    "@dataclass\n",
    "class AcquisitionEvidence:\n",
    "    total_ms2: int = 0\n",
    "    dda_selectedIon_cnt1: int = 0\n",
    "    dda_selectedIon_cnt_gt1: int = 0\n",
    "    dia_iso_no_selected: int = 0\n",
    "    ms2_no_precursor: int = 0\n",
    "    selectedIonList_counts: Counter = field(default_factory=Counter)\n",
    "    selectedIon_mz_min: float = math.inf\n",
    "    selectedIon_mz_max: float = -math.inf\n",
    "    selectedIon_seen: int = 0\n",
    "    selectedIon_mz_sample: Reservoir = field(default_factory=lambda: Reservoir(200))\n",
    "\n",
    "    def record_mz(self, mz: float):\n",
    "        self.selectedIon_seen += 1\n",
    "        if mz < self.selectedIon_mz_min:\n",
    "            self.selectedIon_mz_min = mz\n",
    "        if mz > self.selectedIon_mz_max:\n",
    "            self.selectedIon_mz_max = mz\n",
    "        self.selectedIon_mz_sample.add(mz)\n",
    "\n",
    "@dataclass\n",
    "class StructureReport:\n",
    "    adjacency: Dict[str, set] = field(default_factory=lambda: defaultdict(set))\n",
    "    tag_counts: Counter = field(default_factory=Counter)\n",
    "    def add_edge(self, parent: str, child: str):\n",
    "        self.adjacency[parent].add(child)\n",
    "    def add_tag(self, tag: str):\n",
    "        self.tag_counts[tag] += 1\n",
    "    def as_dict(self) -> Dict[str, List[str]]:\n",
    "        return {k: sorted(list(v)) for k, v in self.adjacency.items()}\n",
    "\n",
    "\n",
    "def _cv_params(elem) -> List[Dict[str, Any]]:\n",
    "    out = []\n",
    "    for cv in elem.findall(get_ns_tag('cvParam')) or elem.findall('cvParam'):\n",
    "        out.append({\n",
    "            'accession': cv.get('accession'),\n",
    "            'name': cv.get('name'),\n",
    "            'value': cv.get('value'),\n",
    "            'unitName': cv.get('unitName'),\n",
    "        })\n",
    "    return out\n",
    "\n",
    "def _first_cv_by_name(params: List[Dict[str, Any]], needle: str):\n",
    "    n = needle.lower()\n",
    "    for p in params:\n",
    "        if n in (p.get('name') or '').lower():\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "def _get_cv_value_by_accession(elem, accession: str) -> Optional[str]:\n",
    "    for cv in _findall(elem, \".//{*}cvParam\"):\n",
    "        if cv.get('accession') == accession:\n",
    "            return cv.get('value')\n",
    "    return None\n",
    "\n",
    "\n",
    "def _convert_scan_time_seconds(scan_elem) -> Optional[float]:\n",
    "    if scan_elem is None:\n",
    "        return None\n",
    "    params = _cv_params(scan_elem)\n",
    "    p = _first_cv_by_name(params, 'scan start time')\n",
    "    if not p:\n",
    "        return None\n",
    "    try:\n",
    "        v = float(p.get('value')) if p.get('value') is not None else None\n",
    "    except ValueError:\n",
    "        return None\n",
    "    if v is None:\n",
    "        return None\n",
    "    unit = (p.get('unitName') or '').lower()\n",
    "    if 'minute' in unit:\n",
    "        return v * 60.0\n",
    "    return v\n",
    "\n",
    "\n",
    "def _update_compression_bitdepth_counts(bda_elem, compression_counts: Dict[str, int], bit_counts: Dict[str, int]):\n",
    "    params = _cv_params(bda_elem)\n",
    "    names = [(p.get('name') or '').lower() for p in params]\n",
    "    if any('zlib' in n for n in names):\n",
    "        compression_counts['zlib'] = compression_counts.get('zlib', 0) + 1\n",
    "    else:\n",
    "        compression_counts['none'] = compression_counts.get('none', 0) + 1\n",
    "    if any('64-bit' in n for n in names):\n",
    "        bit_counts['64'] = bit_counts.get('64', 0) + 1\n",
    "    elif any('32-bit' in n for n in names):\n",
    "        bit_counts['32'] = bit_counts.get('32', 0) + 1\n",
    "\n",
    "\n",
    "def analyze_stream(mzml_path: Path, max_spectra: int = 0,\n",
    "                   acq_dda_thr: float = 0.80, acq_dia_thr: float = 0.80) -> Tuple[MzMLSummary, Dict[str, Any], Dict[str, Any]]:\n",
    "    start = time.time()\n",
    "    logger.info('parse_start', file=str(mzml_path))\n",
    "\n",
    "    summary = MzMLSummary(\n",
    "        file_path=str(mzml_path),\n",
    "        file_size_bytes=mzml_path.stat().st_size,\n",
    "        parser_backend=PARSER_BACKEND,\n",
    "    )\n",
    "    ev = AcquisitionEvidence()\n",
    "    structure = StructureReport()\n",
    "\n",
    "    iter_kwargs = get_iterparse_kwargs()\n",
    "    with open(mzml_path, 'rb') as f:\n",
    "        if PARSER_BACKEND == 'lxml':\n",
    "            context = ET.iterparse(f, events=('start','end'), **iter_kwargs)\n",
    "        else:\n",
    "            context = ET.iterparse(f, events=('start','end'))\n",
    "        stack: List[str] = []\n",
    "        processed = 0\n",
    "        for event, elem in context:\n",
    "            tag = _local(elem.tag)\n",
    "            if event == 'start':\n",
    "                structure.add_tag(tag)\n",
    "                if stack:\n",
    "                    structure.add_edge(stack[-1], tag)\n",
    "                stack.append(tag)\n",
    "                if tag == 'mzML':\n",
    "                    summary.mzml_id = elem.get('id')\n",
    "                    summary.mzml_version = elem.get('version')\n",
    "                elif tag == 'cv':\n",
    "                    summary.cv_count += 1\n",
    "                elif tag == 'software':\n",
    "                    summary.software_count += 1\n",
    "                elif tag == 'instrumentConfiguration':\n",
    "                    summary.instrument_count += 1\n",
    "                elif tag == 'dataProcessing':\n",
    "                    summary.data_processing_count += 1\n",
    "                elif tag == 'run':\n",
    "                    summary.run_id = elem.get('id')\n",
    "                    summary.start_timestamp = elem.get('startTimeStamp')\n",
    "                continue\n",
    "\n",
    "            # event == 'end'\n",
    "            if tag == 'spectrum':\n",
    "                if max_spectra > 0 and summary.spectra_sampled >= max_spectra:\n",
    "                    elem.clear()\n",
    "                    stack.pop();\n",
    "                    continue\n",
    "\n",
    "                summary.spectra_sampled += 1\n",
    "                processed += 1\n",
    "\n",
    "                # ms level, polarity, centroid/profile, TIC, base peaks\n",
    "                params = _cv_params(elem)\n",
    "                p_ms = _first_cv_by_name(params, 'ms level')\n",
    "                ms_level = int(p_ms.get('value')) if p_ms and p_ms.get('value') else None\n",
    "                if ms_level is not None:\n",
    "                    summary.ms_level_distribution[ms_level] = summary.ms_level_distribution.get(ms_level, 0) + 1\n",
    "                if _first_cv_by_name(params, 'centroid'):\n",
    "                    summary.centroid_count += 1\n",
    "                if _first_cv_by_name(params, 'profile'):\n",
    "                    summary.profile_count += 1\n",
    "                p_tic = _first_cv_by_name(params, 'total ion current')\n",
    "                tic = float(p_tic.get('value')) if p_tic and p_tic.get('value') else None\n",
    "                if tic is not None:\n",
    "                    if summary.tic_range is None:\n",
    "                        summary.tic_range = (tic, tic)\n",
    "                    else:\n",
    "                        summary.tic_range = (min(summary.tic_range[0], tic), max(summary.tic_range[1], tic))\n",
    "                p_bpmz = _first_cv_by_name(params, 'base peak m/z')\n",
    "                bpmz = float(p_bpmz.get('value')) if p_bpmz and p_bpmz.get('value') else None\n",
    "                if bpmz is not None:\n",
    "                    if summary.base_peak_mz_range is None:\n",
    "                        summary.base_peak_mz_range = (bpmz, bpmz)\n",
    "                    else:\n",
    "                        summary.base_peak_mz_range = (min(summary.base_peak_mz_range[0], bpmz), max(summary.base_peak_mz_range[1], bpmz))\n",
    "                p_bpint = _first_cv_by_name(params, 'base peak intensity')\n",
    "                bpint = float(p_bpint.get('value')) if p_bpint and p_bpint.get('value') else None\n",
    "                if bpint is not None:\n",
    "                    if summary.base_peak_intensity_range is None:\n",
    "                        summary.base_peak_intensity_range = (bpint, bpint)\n",
    "                    else:\n",
    "                        summary.base_peak_intensity_range = (min(summary.base_peak_intensity_range[0], bpint), max(summary.base_peak_intensity_range[1], bpint))\n",
    "\n",
    "                # RT from scanList/scan\n",
    "                scan_list = elem.find(get_ns_tag('scanList')) or elem.find('scanList')\n",
    "                rt = None\n",
    "                if scan_list is not None:\n",
    "                    scan = scan_list.find(get_ns_tag('scan')) or scan_list.find('scan')\n",
    "                    rt = _convert_scan_time_seconds(scan)\n",
    "                    if rt is not None:\n",
    "                        if summary.rt_range is None:\n",
    "                            summary.rt_range = (rt, rt)\n",
    "                        else:\n",
    "                            summary.rt_range = (min(summary.rt_range[0], rt), max(summary.rt_range[1], rt))\n",
    "\n",
    "                # Acquisition evidence on MS2+\n",
    "                ms_level_val = _get_cv_value_by_accession(elem, ACC_MS_LEVEL)\n",
    "                try:\n",
    "                    ms_level_acc = int(ms_level_val) if ms_level_val is not None else None\n",
    "                except ValueError:\n",
    "                    ms_level_acc = None\n",
    "                if ms_level_acc and ms_level_acc >= 2:\n",
    "                    ev.total_ms2 += 1\n",
    "                    precursors = list(_findall(elem, \".//{*}precursor\"))\n",
    "                    if not precursors:\n",
    "                        ev.ms2_no_precursor += 1\n",
    "                    seen_selected = False\n",
    "                    seen_dia = False\n",
    "                    for prec in precursors:\n",
    "                        sel_list = prec.find('./{*}selectedIonList')\n",
    "                        if sel_list is not None:\n",
    "                            try:\n",
    "                                cnt = int(sel_list.get('count', '0'))\n",
    "                            except ValueError:\n",
    "                                cnt = 0\n",
    "                            ev.selectedIonList_counts[cnt] += 1\n",
    "                            if cnt == 1:\n",
    "                                ev.dda_selectedIon_cnt1 += 1\n",
    "                                seen_selected = True\n",
    "                            elif cnt > 1:\n",
    "                                ev.dda_selectedIon_cnt_gt1 += 1\n",
    "                                seen_selected = True\n",
    "                            sel = sel_list.find('./{*}selectedIon')\n",
    "                            if sel is not None:\n",
    "                                val = _get_cv_value_by_accession(sel, ACC_SELECTED_ION_MZ)\n",
    "                                if val is not None:\n",
    "                                    try:\n",
    "                                        ev.record_mz(float(val))\n",
    "                                    except ValueError:\n",
    "                                        pass\n",
    "                        iso = prec.find('./{*}isolationWindow')\n",
    "                        if iso is not None and not seen_selected:\n",
    "                            # Count DIA-like if target present\n",
    "                            has_target = _get_cv_value_by_accession(iso, ACC_ISO_TARGET) is not None\n",
    "                            if has_target:\n",
    "                                seen_dia = True\n",
    "                    if seen_dia:\n",
    "                        ev.dia_iso_no_selected += 1\n",
    "\n",
    "                # compression/bit-depth from binaryDataArrayList\n",
    "                bdal = elem.find(get_ns_tag('binaryDataArrayList')) or elem.find('binaryDataArrayList')\n",
    "                if bdal is not None:\n",
    "                    for bda in bdal.findall(get_ns_tag('binaryDataArray')) or bdal.findall('binaryDataArray'):\n",
    "                        _update_compression_bitdepth_counts(bda, summary.compression_counts, summary.bit_depth_counts)\n",
    "\n",
    "                elem.clear()\n",
    "                while hasattr(elem, 'getprevious') and elem.getprevious() is not None:\n",
    "                    try:\n",
    "                        del elem.getparent()[0]\n",
    "                    except Exception:\n",
    "                        break\n",
    "\n",
    "            # pop stack\n",
    "            if stack:\n",
    "                stack.pop()\n",
    "\n",
    "    summary.parse_duration_sec = time.time() - start\n",
    "\n",
    "    # Total spectra from ms_level_distribution if not set elsewhere\n",
    "    summary.total_spectra = sum(summary.ms_level_distribution.values())\n",
    "\n",
    "    # Acquisition classification\n",
    "    if ev.total_ms2 == 0:\n",
    "        classification = 'UNKNOWN'\n",
    "        dda_ratio = dia_ratio = 0.0\n",
    "    else:\n",
    "        dda_ratio = ev.dda_selectedIon_cnt1 / ev.total_ms2\n",
    "        dia_ratio = ev.dia_iso_no_selected / ev.total_ms2\n",
    "        if dda_ratio >= acq_dda_thr and dia_ratio <= (1 - acq_dda_thr):\n",
    "            classification = 'DDA'\n",
    "        elif dia_ratio >= acq_dia_thr and dda_ratio <= (1 - acq_dia_thr):\n",
    "            classification = 'DIA'\n",
    "        else:\n",
    "            classification = 'MIXED'\n",
    "\n",
    "    run_summary = asdict(summary)\n",
    "    # normalize tuple ranges to lists for JSON friendliness\n",
    "    def _tuple_to_list(d: Dict[str, Any], keys: List[str]):\n",
    "        for k in keys:\n",
    "            if d.get(k) is not None:\n",
    "                d[k] = list(d[k])\n",
    "    _tuple_to_list(run_summary, ['tic_range','base_peak_mz_range','base_peak_intensity_range','rt_range'])\n",
    "\n",
    "    acquisition_report = {\n",
    "        'classification': classification,\n",
    "        'total_ms2': ev.total_ms2,\n",
    "        'evidence': {\n",
    "            'dda_selectedIon_cnt1': ev.dda_selectedIon_cnt1,\n",
    "            'dda_selectedIon_cnt_gt1': ev.dda_selectedIon_cnt_gt1,\n",
    "            'dia_iso_no_selected': ev.dia_iso_no_selected,\n",
    "            'ms2_no_precursor': ev.ms2_no_precursor,\n",
    "        },\n",
    "        'ratios': {\n",
    "            'dda_selectedIon_cnt1_per_ms2': (ev.dda_selectedIon_cnt1 / ev.total_ms2) if ev.total_ms2 else 0.0,\n",
    "            'dia_iso_no_selected_per_ms2': (ev.dia_iso_no_selected / ev.total_ms2) if ev.total_ms2 else 0.0,\n",
    "        },\n",
    "        'thresholds': {\n",
    "            'dda_ratio_threshold': acq_dda_thr,\n",
    "            'dia_ratio_threshold': acq_dia_thr,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    selected_ion_summary = {\n",
    "        'selectedIonList_count_histogram': dict(ev.selectedIonList_counts),\n",
    "        'selectedIon_seen': ev.selectedIon_seen,\n",
    "        'selectedIon_mz_min': (None if ev.selectedIon_seen == 0 else ev.selectedIon_mz_min),\n",
    "        'selectedIon_mz_max': (None if ev.selectedIon_seen == 0 else ev.selectedIon_mz_max),\n",
    "        'selectedIon_mz_sample': ev.selectedIon_mz_sample.sample(),\n",
    "    }\n",
    "\n",
    "    structure_report = {\n",
    "        'elements_hierarchy': structure.as_dict(),\n",
    "        'element_occurrences': dict(structure.tag_counts),\n",
    "        'selected_ion_summary': selected_ion_summary,\n",
    "    }\n",
    "\n",
    "    logger.info('parse_done', duration_sec=summary.parse_duration_sec, spectra=summary.spectra_sampled)\n",
    "    return run_summary, acquisition_report, structure_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2222cedd",
   "metadata": {},
   "source": [
    "## 7) Execute Analysis (Run All)\n",
    "\n",
    "Validates inputs, runs the analyzer, and keeps dicts in memory for writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ecf725a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"ts\": 1767618040.5465841, \"level\": \"INFO\", \"event\": \"parse_start\", \"file\": \"/Users/maxvandenboom/Docs/Coding/AI/ProfileTensor/data/2449SAB_0002_A1.mzML\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ql/9dgs6k1j3d35q0rnf__xlhd00000gn/T/ipykernel_46236/2476699710.py:201: FutureWarning: Truth-testing of elements was a source of confusion and will always return True in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  scan_list = elem.find(get_ns_tag('scanList')) or elem.find('scanList')\n",
      "/var/folders/ql/9dgs6k1j3d35q0rnf__xlhd00000gn/T/ipykernel_46236/2476699710.py:204: FutureWarning: Truth-testing of elements was a source of confusion and will always return True in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  scan = scan_list.find(get_ns_tag('scan')) or scan_list.find('scan')\n",
      "/var/folders/ql/9dgs6k1j3d35q0rnf__xlhd00000gn/T/ipykernel_46236/2476699710.py:257: FutureWarning: Truth-testing of elements was a source of confusion and will always return True in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  bdal = elem.find(get_ns_tag('binaryDataArrayList')) or elem.find('binaryDataArrayList')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"ts\": 1767618042.173748, \"level\": \"INFO\", \"event\": \"parse_done\", \"duration_sec\": 1.6271018981933594, \"spectra\": 16228}\n",
      "{\n",
      "  \"classification\": \"DDA\",\n",
      "  \"spectra_sampled\": 16228,\n",
      "  \"ms_level_distribution\": {\n",
      "    \"1\": 2723,\n",
      "    \"2\": 13505\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Validate path and run\n",
    "a_mzml = validate_path(MZML_FILE, allowed_root=None)\n",
    "run_summary, acquisition_report, structure_report = analyze_stream(\n",
    "    a_mzml,\n",
    "    max_spectra=MAX_SPECTRA_SAMPLE,\n",
    "    acq_dda_thr=ACQ_DDA_THRESHOLD,\n",
    "    acq_dia_thr=ACQ_DIA_THRESHOLD,\n",
    ")\n",
    "print(json.dumps({\n",
    "    'classification': acquisition_report['classification'],\n",
    "    'spectra_sampled': run_summary.get('spectra_sampled'),\n",
    "    'ms_level_distribution': run_summary.get('ms_level_distribution')\n",
    "}, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe87766",
   "metadata": {},
   "source": [
    "## 8) Write Artifacts (JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "650f16ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote:\n",
      "- /Users/maxvandenboom/Docs/Coding/AI/ProfileTensor/out/2449SAB_0002_A1/run_summary.json\n",
      "- /Users/maxvandenboom/Docs/Coding/AI/ProfileTensor/out/2449SAB_0002_A1/acquisition_report.json\n",
      "- /Users/maxvandenboom/Docs/Coding/AI/ProfileTensor/out/2449SAB_0002_A1/structure_report.json\n"
     ]
    }
   ],
   "source": [
    "with open(RUN_SUMMARY_JSON, 'w', encoding='utf-8') as f:\n",
    "    json.dump(run_summary, f, indent=2)\n",
    "with open(ACQ_REPORT_JSON, 'w', encoding='utf-8') as f:\n",
    "    json.dump(acquisition_report, f, indent=2)\n",
    "with open(STRUCTURE_JSON, 'w', encoding='utf-8') as f:\n",
    "    json.dump(structure_report, f, indent=2)\n",
    "print(\"Wrote:\")\n",
    "print(\"-\", RUN_SUMMARY_JSON)\n",
    "print(\"-\", ACQ_REPORT_JSON)\n",
    "print(\"-\", STRUCTURE_JSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db1332d",
   "metadata": {},
   "source": [
    "## 9) Stream Spectra Metadata to CSV/Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65acfa6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ql/9dgs6k1j3d35q0rnf__xlhd00000gn/T/ipykernel_46236/2140636903.py:35: FutureWarning: Truth-testing of elements was a source of confusion and will always return True in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  scan_list = elem.find(get_ns_tag('scanList')) or elem.find('scanList')\n",
      "/var/folders/ql/9dgs6k1j3d35q0rnf__xlhd00000gn/T/ipykernel_46236/2140636903.py:38: FutureWarning: Truth-testing of elements was a source of confusion and will always return True in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  scan = scan_list.find(get_ns_tag('scan')) or scan_list.find('scan')\n",
      "/var/folders/ql/9dgs6k1j3d35q0rnf__xlhd00000gn/T/ipykernel_46236/2140636903.py:45: FutureWarning: Truth-testing of elements was a source of confusion and will always return True in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  precursor_list = elem.find(get_ns_tag('precursorList')) or elem.find('precursorList')\n",
      "/var/folders/ql/9dgs6k1j3d35q0rnf__xlhd00000gn/T/ipykernel_46236/2140636903.py:47: FutureWarning: Truth-testing of elements was a source of confusion and will always return True in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  prec = precursor_list.find(get_ns_tag('precursor')) or precursor_list.find('precursor')\n",
      "/var/folders/ql/9dgs6k1j3d35q0rnf__xlhd00000gn/T/ipykernel_46236/2140636903.py:49: FutureWarning: Truth-testing of elements was a source of confusion and will always return True in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  sel_list = prec.find(get_ns_tag('selectedIonList')) or prec.find('selectedIonList')\n",
      "/var/folders/ql/9dgs6k1j3d35q0rnf__xlhd00000gn/T/ipykernel_46236/2140636903.py:57: FutureWarning: Truth-testing of elements was a source of confusion and will always return True in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  sel = sel_list.find(get_ns_tag('selectedIon')) or sel_list.find('selectedIon')\n",
      "/var/folders/ql/9dgs6k1j3d35q0rnf__xlhd00000gn/T/ipykernel_46236/2140636903.py:65: FutureWarning: Truth-testing of elements was a source of confusion and will always return True in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  iso = prec.find(get_ns_tag('isolationWindow')) or prec.find('isolationWindow')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote spectra metadata (16228 rows) to /Users/maxvandenboom/Docs/Coding/AI/ProfileTensor/out/2449SAB_0002_A1/spectra_meta.csv\n"
     ]
    }
   ],
   "source": [
    "def stream_spectra_meta(mzml_path: Path, max_spectra: int = 0):\n",
    "    iter_kwargs = get_iterparse_kwargs()\n",
    "    records = 0\n",
    "    \n",
    "    f = open(SPECTRA_META_CSV, 'w', newline='', encoding='utf-8')\n",
    "    w = csv.writer(f)\n",
    "    header = ['spectrum_index','spectrum_id','ms_level','rt_seconds','polarity','centroid','tic','base_peak_mz','base_peak_intensity','precursor_selected_ion_mz','isolation_window_target_mz','acquisition_mode_hint']\n",
    "    w.writerow(header)\n",
    "\n",
    "    with open(mzml_path, 'rb') as fin:\n",
    "        if PARSER_BACKEND == 'lxml':\n",
    "            context = ET.iterparse(fin, events=('end',), **iter_kwargs)\n",
    "        else:\n",
    "            context = ET.iterparse(fin, events=('end',))\n",
    "        for event, elem in context:\n",
    "            if strip_ns(elem.tag) != 'spectrum':\n",
    "                continue\n",
    "            if max_spectra > 0 and records >= max_spectra:\n",
    "                break\n",
    "\n",
    "            idx = int(elem.get('index', '0'))\n",
    "            sid = elem.get('id')\n",
    "            params = _cv_params(elem)\n",
    "            p_ms = _first_cv_by_name(params, 'ms level')\n",
    "            ms_level = int(p_ms.get('value')) if p_ms and p_ms.get('value') else None\n",
    "            pol = 'positive' if _first_cv_by_name(params, 'positive') else ('negative' if _first_cv_by_name(params, 'negative') else None)\n",
    "            centroid = True if _first_cv_by_name(params, 'centroid') else (False if _first_cv_by_name(params, 'profile') else None)\n",
    "            p_tic = _first_cv_by_name(params, 'total ion current')\n",
    "            tic = float(p_tic.get('value')) if p_tic and p_tic.get('value') else None\n",
    "            p_bpmz = _first_cv_by_name(params, 'base peak m/z')\n",
    "            bpmz = float(p_bpmz.get('value')) if p_bpmz and p_bpmz.get('value') else None\n",
    "            p_bpint = _first_cv_by_name(params, 'base peak intensity')\n",
    "            bpint = float(p_bpint.get('value')) if p_bpint and p_bpint.get('value') else None\n",
    "\n",
    "            scan_list = elem.find(get_ns_tag('scanList')) or elem.find('scanList')\n",
    "            rt = None\n",
    "            if scan_list is not None:\n",
    "                scan = scan_list.find(get_ns_tag('scan')) or scan_list.find('scan')\n",
    "                rt = _convert_scan_time_seconds(scan)\n",
    "\n",
    "            # precursor info\n",
    "            precursor_mz = None\n",
    "            iso_target = None\n",
    "            acq_hint = None\n",
    "            precursor_list = elem.find(get_ns_tag('precursorList')) or elem.find('precursorList')\n",
    "            if precursor_list is not None:\n",
    "                prec = precursor_list.find(get_ns_tag('precursor')) or precursor_list.find('precursor')\n",
    "                if prec is not None:\n",
    "                    sel_list = prec.find(get_ns_tag('selectedIonList')) or prec.find('selectedIonList')\n",
    "                    if sel_list is not None:\n",
    "                        try:\n",
    "                            cnt = int(sel_list.get('count','0'))\n",
    "                        except ValueError:\n",
    "                            cnt = 0\n",
    "                        if cnt >= 1:\n",
    "                            acq_hint = 'DDA'\n",
    "                        sel = sel_list.find(get_ns_tag('selectedIon')) or sel_list.find('selectedIon')\n",
    "                        if sel is not None:\n",
    "                            val = _get_cv_value_by_accession(sel, ACC_SELECTED_ION_MZ)\n",
    "                            if val is not None:\n",
    "                                try:\n",
    "                                    precursor_mz = float(val)\n",
    "                                except ValueError:\n",
    "                                    pass\n",
    "                    iso = prec.find(get_ns_tag('isolationWindow')) or prec.find('isolationWindow')\n",
    "                    if iso is not None:\n",
    "                        val = _get_cv_value_by_accession(iso, ACC_ISO_TARGET)\n",
    "                        if val is not None:\n",
    "                            try:\n",
    "                                iso_target = float(val)\n",
    "                                if acq_hint is None:\n",
    "                                    acq_hint = 'DIA'\n",
    "                            except ValueError:\n",
    "                                pass\n",
    "\n",
    "            row = [idx, sid, ms_level, rt, pol, centroid, tic, bpmz, bpint, precursor_mz, iso_target, acq_hint]\n",
    "            w.writerow(row)\n",
    "            records += 1\n",
    "            elem.clear()\n",
    "            while hasattr(elem, 'getprevious') and elem.getprevious() is not None:\n",
    "                try:\n",
    "                    del elem.getparent()[0]\n",
    "                except Exception:\n",
    "                    break\n",
    "\n",
    "    f.close()\n",
    "    return SPECTRA_META_CSV, records\n",
    "\n",
    "meta_path, meta_n = stream_spectra_meta(a_mzml, MAX_SPECTRA_SAMPLE)\n",
    "print(f\"Wrote spectra metadata ({meta_n} rows) to {meta_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6e618f",
   "metadata": {},
   "source": [
    "## 10) Validate Outputs (Quick Preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9389365b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: DDA\n",
      "Total MS2: 13505\n",
      "MS level distribution: {'1': 2723, '2': 13505}\n",
      "RT range (s): [0.075, 899.82499999998]\n",
      "Compression: {'zlib': 32456}\n",
      "Bit depth: {'64': 16228, '32': 16228}\n",
      "spectra_meta.csv rows (first chunk): 200\n",
      "   spectrum_index                             spectrum_id  ms_level  rt_seconds  polarity  centroid       tic  base_peak_mz  base_peak_intensity  precursor_selected_ion_mz  isolation_window_target_mz acquisition_mode_hint\n",
      "0               0  sample=1 period=1 cycle=1 experiment=1         1       0.075  positive      True  325240.0    198.095246              37926.0                        NaN                         NaN                   NaN\n",
      "1               1  sample=1 period=1 cycle=1 experiment=2         2       0.143  positive      True  722706.0     42.034084             183094.0                     105.15                      105.15                   DDA\n",
      "2               2  sample=1 period=1 cycle=1 experiment=3         2       0.184  positive      True  631674.0    166.029298              15635.0                     202.30                      202.30                   DDA\n",
      "3               3  sample=1 period=1 cycle=1 experiment=4         2       0.225  positive      True  169214.0     46.066514               2091.0                     283.50                      283.50                   DDA\n",
      "4               4  sample=1 period=1 cycle=1 experiment=5         2       0.266  positive      True  409888.0    381.206962               5784.0                     394.10                      394.10                   DDA\n",
      "5               5  sample=1 period=1 cycle=1 experiment=6         2       0.307  positive      True  382833.0    278.118277               2433.0                     637.40                      637.40                   DDA\n",
      "6               6  sample=1 period=1 cycle=2 experiment=1         1       0.403  positive      True  773362.0    166.028289              22959.0                        NaN                         NaN                   NaN\n",
      "7               7  sample=1 period=1 cycle=2 experiment=2         2       0.473  positive      True  695701.0     42.034084             148669.0                     105.15                      105.15                   DDA\n",
      "8               8  sample=1 period=1 cycle=2 experiment=3         2       0.514  positive      True  591019.0    166.029298               9565.0                     202.30                      202.30                   DDA\n",
      "9               9  sample=1 period=1 cycle=2 experiment=4         2       0.555  positive      True  158417.0     46.064609               2361.0                     283.50                      283.50                   DDA\n",
      "Basic checks passed.\n"
     ]
    }
   ],
   "source": [
    "# Quick previews\n",
    "try:\n",
    "    with open(RUN_SUMMARY_JSON, 'r', encoding='utf-8') as f:\n",
    "        rs = json.load(f)\n",
    "    with open(ACQ_REPORT_JSON, 'r', encoding='utf-8') as f:\n",
    "        ar = json.load(f)\n",
    "    with open(STRUCTURE_JSON, 'r', encoding='utf-8') as f:\n",
    "        sr = json.load(f)\n",
    "    print('Classification:', ar.get('classification'))\n",
    "    print('Total MS2:', ar.get('total_ms2'))\n",
    "    print('MS level distribution:', rs.get('ms_level_distribution'))\n",
    "    print('RT range (s):', rs.get('rt_range'))\n",
    "    print('Compression:', rs.get('compression_counts'))\n",
    "    print('Bit depth:', rs.get('bit_depth_counts'))\n",
    "    \n",
    "    if SPECTRA_META_CSV.exists():\n",
    "        df = pd.read_csv(SPECTRA_META_CSV, nrows=max(PREVIEW_ROWS, 200))\n",
    "        print('spectra_meta.csv rows (first chunk):', len(df))\n",
    "        print(df.head(PREVIEW_ROWS).to_string())\n",
    "    else:\n",
    "        print('No spectra metadata file found yet.')\n",
    "\n",
    "    # Smoke checks\n",
    "    cls_ok = ar.get('classification') in {'DDA','DIA','MIXED','UNKNOWN'}\n",
    "    assert cls_ok, 'Classification out of range'\n",
    "    for k in ['cv_count','software_count','instrument_count','data_processing_count']:\n",
    "        v = rs.get(k, 0)\n",
    "        assert isinstance(v, int) and v >= 0\n",
    "    print('Basic checks passed.')\n",
    "except Exception as e:\n",
    "    print('Preview error:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcb8a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "profiletensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
